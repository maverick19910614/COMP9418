{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains and Hidden Markov Models\n",
    "\n",
    "**COMP9418-20T3, W05 Tutorial**\n",
    "\n",
    "- Instructor: Gustavo Batista\n",
    "- School of Computer Science and Engineering, UNSW Sydney \n",
    "- Questions by Gustavo Batista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's tutorial, we will explore models that use the Markovian assumptions, in particular Markov chains and Hidden Markov Models. We will implement the forward and Viterbi algorithms and use them to gain intuition about the convergence of Markov chains, and the probabilitic queries these algorithms can answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "You will need certain packages installed to run this notebook.\n",
    "\n",
    "If you are using ``conda``'s default\n",
    "[full installation](https://conda.io/docs/install/full.html),\n",
    "these requirements should all be satisfied already.\n",
    "\n",
    "If you are using ``virtualenv`` or other native package management,\n",
    "you may need to run these commands:\n",
    "\n",
    "```python\n",
    "pip3 install numpy matplotlib\n",
    "```\n",
    "\n",
    "To render a visualization of some graphical models, you also need to install Graphviz [download page](http://www.graphviz.org/download). We have already used this library in Tutorial 1, thus, you should have it installed. If you do not have it and use the conda installation, then use the command ```conda install python-graphviz```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have done all that, we\n",
    "import some useful modules for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make division default to floating-point, saving confusion\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# combinatorics\n",
    "from itertools import product, combinations\n",
    "# ordered dictionaries are useful for keeping ordered sets of varibles\n",
    "from collections import OrderedDict as odict\n",
    "# table formating for screen output\n",
    "from tabulate import tabulate\n",
    "#visualise graphs\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chains\n",
    "\n",
    "Let's start implementing the mini-forward algorithm for Markov chains. We will use this algorithm to calculate the probability of a sequence of events as well as testing the convergence of some chains.\n",
    "\n",
    "Remember from the course slides that a Markov chain (as well as the Hidden Markov Model) is a Dynamic Bayesian Network (DBN). It means that this network \"grows\", i.e., we can add nodes as we iterate over time or space. We need to specify a notation to indicate time passage. Similarly to the slides, we use $t-1$ and $t$ appended to the variables names to designate the previous time and present time.\n",
    "\n",
    "We can use the example from the slides to introduce the notation and write the first transition tables.\n",
    "\n",
    "![](./img/weather.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define a Markov chain, we need to set the outcomeSpace as well as initial state and the transition probabilities. We will write the first two and let the third one as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible outcomes, by variable\n",
    "outcomeSpace = {\n",
    "    'Weather_t-1':('sun','rain'),    \n",
    "    'Weather_t':('sun','rain'),\n",
    "}\n",
    "\n",
    "# The start state, in this case let's assume we start in a sunny day\n",
    "weatherStart = {\n",
    "    'dom': ('Weather',), \n",
    "    'table': odict([\n",
    "        (('sun',), 1.0),\n",
    "        (('rain',), 0.0),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Now, it is your turn. Define the transition probability table according to the figure above. We have created an initial table for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherTransition = {\n",
    "    'dom': ('Weather_t-1', 'Weather_t'), \n",
    "    'table': odict([\n",
    "        (('sun','sun'), None),\n",
    "        (('sun','rain'), None),\n",
    "        (('rain','sun'), None),\n",
    "        (('rain','rain'), None),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double-check our work with the `graphviz` library. The source code bellow draws a state transition graph based on the `weatherTransition` table that you just defined. Compare the `graphviz` plot with the slide figure to confirm your state transition probabilities are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = Digraph(engine=\"neato\", comment='Weather Markov chain')\n",
    "dot.attr(overlap=\"false\", splines=\"false\")\n",
    "\n",
    "pos = {\n",
    "    'sun': '0,1!',\n",
    "    'rain': '0,0!',    \n",
    "}\n",
    "\n",
    "for v in outcomeSpace['Weather_t']:\n",
    "    dot.node(v, pos=pos[v])\n",
    "\n",
    "for v in outcomeSpace['Weather_t']:\n",
    "    for w in outcomeSpace['Weather_t']:\n",
    "        dot.edge(v, w, str(weatherTransition['table'][(v,w)]))\n",
    "\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now implement the mini-forward algoritm for Markov chains. Remember from the slides that the update rule for the forward simulation is the following:\n",
    "\n",
    "$P(x_t) = \\sum_{x_{t-1}}P(x_t | x_{t-1})P(x_{t-1})$\n",
    "\n",
    "- $P(x_{t-1})$ is the previous state probability table.\n",
    "\n",
    "- $P(x_t | x_{t-1})$ is the transition probability table such as the one you defined in the previous exercise.\n",
    "\n",
    "- $P(x_t)$ is the current state probability table.\n",
    "\n",
    "From this equation, it is clear we need two basic operations. One is the multiplication of factors (probability tables) that we implemented in a previous tutorial as a `joint` operation. The second one summing one variable out that we implemented as a `marginalize` operation.\n",
    "\n",
    "Let's bring these two functions as well as the `prob` and `printFactor` subroutines we implemented in previous tutorials. We recommend that you use your implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printFactor(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, a factor to print on screen\n",
    "    \"\"\"\n",
    "    # Create a empty list that we will fill in with the probability table entries\n",
    "    table = list()\n",
    "    \n",
    "    # Iterate over all keys and probability values in the table\n",
    "    for key, item in f['table'].items():\n",
    "        # Convert the tuple to a list to be able to manipulate it\n",
    "        k = list(key)\n",
    "        # Append the probability value to the list with key values\n",
    "        k.append(item)\n",
    "        # Append an entire row to the table\n",
    "        table.append(k)\n",
    "    # dom is used as table header. We need it converted to list\n",
    "    dom = list(f['dom'])\n",
    "    # Append a 'Pr' to indicate the probabity column\n",
    "    dom.append('Pr')\n",
    "    print(tabulate(table,headers=dom,tablefmt='orgtbl'))\n",
    "\n",
    "def prob(factor, *entry):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, a dictionary of domain and probability values,\n",
    "    `entry`, a list of values, one for each variable in the same order as specified in the factor domain.\n",
    "    \n",
    "    Returns p(entry)\n",
    "    \"\"\"\n",
    "\n",
    "    return factor['table'][entry]     # insert your code here, 1 line   \n",
    "\n",
    "def join(f1, f2, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f1`, first factor to be joined.\n",
    "    `f2`, second factor to be joined.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor with a join of f1 and f2\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, we need to determine the domain of the new factor. It will be union of the domain in f1 and f2\n",
    "    # But it is important to eliminate the repetitions\n",
    "    common_vars = list(f1['dom']) + list(set(f2['dom']) - set(f1['dom']))\n",
    "    \n",
    "    # We will build a table from scratch, starting with an empty list. Later on, we will transform the list into a odict\n",
    "    table = list()\n",
    "    \n",
    "    # Here is where the magic happens. The product iterator will generate all combinations of varible values \n",
    "    # as specified in outcomeSpace. Therefore, it will naturally respect observed values\n",
    "    for entries in product(*[outcomeSpace[node] for node in common_vars]):\n",
    "        \n",
    "        # We need to map the entries to the domain of the factors f1 and f2\n",
    "        entryDict = dict(zip(common_vars, entries))\n",
    "        f1_entry = (entryDict[var] for var in f1['dom'])\n",
    "        f2_entry = (entryDict[var] for var in f2['dom'])\n",
    "        \n",
    "        # Insert your code here\n",
    "        p1 = prob(f1, *f1_entry)           # Use the fuction prob to calculate the probability in factor f1 for entry f1_entry \n",
    "        p2 = prob(f2, *f2_entry)           # Use the fuction prob to calculate the probability in factor f2 for entry f2_entry \n",
    "        \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, p1 * p2))\n",
    "    return {'dom': tuple(common_vars), 'table': odict(table)}\n",
    "\n",
    "\n",
    "def marginalize(f, var, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be marginalized.\n",
    "    `var`, variable to be summed out.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor f' with dom(f') = dom(f) - {var}\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Let's make a copy of f domain and convert it to a list. We need a list to be able to modify its elements\n",
    "    new_dom = list(f['dom'])\n",
    "    \n",
    "    new_dom.remove(var)            # Remove var from the list new_dom by calling the method remove(). 1 line\n",
    "    table = list()                 # Create an empty list for table. We will fill in table from scratch. 1 line\n",
    "    for entries in product(*[outcomeSpace[node] for node in new_dom]):\n",
    "        s = 0;                     # Initialize the summation variable s. 1 line\n",
    "\n",
    "        # We need to iterate over all possible outcomes of the variable var\n",
    "        for val in outcomeSpace[var]:\n",
    "            # To modify the tuple entries, we will need to convert it to a list\n",
    "            entriesList = list(entries)\n",
    "            # We need to insert the value of var in the right position in entriesList\n",
    "            entriesList.insert(f['dom'].index(var), val)\n",
    "            \n",
    "            p = prob(f, *tuple(entriesList))     # Calculate the probability of factor f for entriesList. 1 line\n",
    "            s = s + p                            # Sum over all values of var by accumulating the sum in s. 1 line\n",
    "            \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, s))\n",
    "    return {'dom': tuple(new_dom), 'table': odict(table)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Let's implement the miniForward algorithm for Markov chains. We start with the online version that makes a single update (one time step). We use the online version to implement the batch one that runs multiple time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miniForwardOnline(f, transition, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor that represents the previous state of the chain.\n",
    "    `transition`, transition probabilities from time t-1 to t.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.\n",
    "    \n",
    "    Returns a new factor that represents the current state of the chain.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make a copy of f so we will not modify the original factor\n",
    "    fPrevious = None                                          # 1 line\n",
    "    # Name of the random variable. f domain should be a list with a single element\n",
    "    randVariable = fPrevious['dom'][0]\n",
    "    # Set the f_previous domain to be a list with a single variable name appended with '_t-1' to indicate previous time step\n",
    "    fPrevious['dom'] = (randVariable + '_t-1', )\n",
    "    # Make the join operation between fPrevious and the transition probability table\n",
    "    fCurrent = None                                           # 1 line\n",
    "    # Marginalize the randVariable_t-1\n",
    "    fCurrent = None                                           # 1 line\n",
    "    # Set the domain of fCurrent to be name of the random variable without time index\n",
    "    fCurrent['dom'] = (randVariable, )\n",
    "    return fCurrent\n",
    "\n",
    "##################\n",
    "# Test code\n",
    "\n",
    "printFactor(miniForwardOnline(weatherStart, weatherTransition, outcomeSpace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should have the following output:\n",
    "\n",
    "```\n",
    "| Weather   |   Pr |\n",
    "|-----------+------|\n",
    "| sun       |  0.9 |\n",
    "| rain      |  0.1 |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the mini-forward online implementation to make a simple batch extension that calls the online subroutine a fixed number of times.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Implement the batch version of the mini-forward algorithm for Markov chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miniForwardBatch(f, transition, outcomeSpace, n):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor that represents the previous state of the chain.\n",
    "    `transition`, transition probabilities from time t-1 to t.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.\n",
    "    `n`, number of time updates\n",
    "    \n",
    "    Returns a new factor that represents the current state of the chain after n time steps.\n",
    "    \"\"\"\n",
    "\n",
    "    # fCurrent is a copy of f, so we will not overwrite f in the for loop\n",
    "    fCurrent = f.copy()\n",
    "    for i in range(n):\n",
    "        # Call miniForwardOnline to update fCurrent\n",
    "        fCurrent = None                                                        # 1 line\n",
    "        # Print fCurrent to debug the results\n",
    "        printFactor(fCurrent)\n",
    "        print()\n",
    "    # return fCurrent\n",
    "    return fCurrent\n",
    "        \n",
    "###################\n",
    "# Test code\n",
    "\n",
    "printFactor(miniForwardBatch(weatherStart, weatherTransition, outcomeSpace, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented your code correctly, you should see the following output:\n",
    "\n",
    "```\n",
    "| Weather   |   Pr |\n",
    "|-----------+------|\n",
    "| sun       |  0.9 |\n",
    "| rain      |  0.1 |\n",
    "\n",
    "| Weather   |   Pr |\n",
    "|-----------+------|\n",
    "| sun       | 0.84 |\n",
    "| rain      | 0.16 |\n",
    "\n",
    "| Weather   |    Pr |\n",
    "|-----------+-------|\n",
    "| sun       | 0.804 |\n",
    "| rain      | 0.196 |\n",
    "\n",
    "| Weather   |    Pr |\n",
    "|-----------+-------|\n",
    "| sun       | 0.804 |\n",
    "| rain      | 0.196 |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now test the convergence of some Markov chains. Remember from the lectures that chains were classified according to two properties:\n",
    "\n",
    "1. Reducibility. An irreducible (or regular) chain has the property that every state is reachable from every state. Therefore the chain has a single stationary distribution. A reducible chain has not such property and, therefore, can have multiple stationary distributions. The general idea is that, if a chain has, say, two disconnected sets of states **A** and **B** and we start in a state $a \\in \\textbf{A}$, then we will never reach a state in **B**. In this case, the stationary distribution will depend on the transition probabilities of the states in **A**. The same occurs if we start in a state $b \\in \\textbf{B}$.\n",
    "\n",
    "2. Periodicity. An irreducible chain is not guaranteed to convergence. To ensure convergence, we need an additional property: aperiodicity. An aperiodic chain avoids alternating forever between states without ever settling in a stationary distribution. A practical issue in that, although irreducible aperiodic chains are guaranteed to converge to a single stationary distribution, the convergence can be very slow, depending on the transition probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Let's implement an additional helper function `miniForwardConvergence` that runs until convergence or a maximum number of iterations. We will establish convergence when the error between two consecutive state probability distributions is smaller than a threshold.\n",
    "\n",
    "Let's start with the implementation of `miniForwardConvergence`. We implemented a helper function `convError` that computes the absolute error between two factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convError(f1, f2, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f1`, factor with the current state probability distribution in the chain.\n",
    "    `f2`, factor with the previous state probability distribution in the chain.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.    \n",
    "    \n",
    "    Returns absolute error between f1 and f2.\n",
    "    \"\"\"\n",
    "    return sum([abs(prob(f1, var) - prob(f2, var)) for var in outcomeSpace[f1['dom'][0]+'_t']])\n",
    "\n",
    "\n",
    "def miniforwardConvergence(f, transition, outcomeSpace, n = 1000, eps = 0.00001):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor that represents the previous state of the chain.\n",
    "    `transition`, transition probabilities from time t-1 to t.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.\n",
    "    `startDistribution`, initial state probability distribution.\n",
    "    `n`, maximum number of time updates.\n",
    "    `eps`, error threshold to determine convergence.\n",
    "    \n",
    "    Returns a new factor that represents the current state of the chain after n time steps or the convergence error is less than eps.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"  Iter Error\\n------ --------\")\n",
    "    # fCurrent is a copy of f, so we will not overwrite f in the for loop\n",
    "    fCurrent = f.copy()\n",
    "    # Set an empty list of error, so we can plot the errors later\n",
    "    errors = []\n",
    "    for i in range(n):\n",
    "        # Call miniForwardOnline to compute fNew\n",
    "        fNew = None                                                                      # 1 line\n",
    "        # Calculate error between fNew and fCurrent using the convError function\n",
    "        error = None                                                                     # 1 line\n",
    "        # Halt the loop if the error is smaller than eps\n",
    "        if (error < eps):\n",
    "            break\n",
    "        # Print a message every 10 iterations to inform the convergence progress\n",
    "        if (i % 10 == 0):\n",
    "            print(\"%6d %1.6f\" % (i, error))\n",
    "        # Store the current error value in a list of error so we can plot it later\n",
    "        errors.append(error)\n",
    "        # Updates fCurrent as fNew\n",
    "        fCurrent = fNew\n",
    "    #Plot the errors\n",
    "    plt.plot(errors, 'ro')\n",
    "    plt.show()\n",
    "\n",
    "    return fCurrent\n",
    "\n",
    "######################\n",
    "# Test code\n",
    "\n",
    "printFactor(miniforwardConvergence(weatherStart, weatherTransition, outcomeSpace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented your code correctly, you should see an output like this:\n",
    "\n",
    "```\n",
    "  Iter Error\n",
    "------ --------\n",
    "     0 0.200000\n",
    "    10 0.001209\n",
    "\n",
    "| Weather   |       Pr |\n",
    "|-----------+----------|\n",
    "| sun       | 0.750009 |\n",
    "| rain      | 0.249991 |\n",
    "```\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Now, we can test the convergence of some Markov chains of the previous tutorial. \n",
    "\n",
    "The first one has the following transition matrix:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "1/2 & 0 & 1/2 & 0 \\\\\n",
    "0 & 1/2 & 0 & 1/2 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "\\end{bmatrix}$\n",
    "    \n",
    "This chain is irreducible since we can reach any state from any state. However, it is periodic since if we start from state 1 in time 1, we reach states 1 and 3 at odd times and 2 and 4 at even times. Its stationary distribution is $(1/6, 2/6, 2/6, 1/6)$.\n",
    "\n",
    "Use the implemented function to confirm that this chain does not converge. Use the next cell to define the necessary variables and call `miniforwardConvergence` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomeSpace_c1 = {\n",
    "    None\n",
    "}\n",
    "\n",
    "transition_c1 = {\n",
    "    None\n",
    "}\n",
    "\n",
    "start_c1 = {\n",
    "    None\n",
    "}\n",
    "\n",
    "printFactor(miniforwardConvergence(start_c1, transition_c1, outcomeSpace_c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second one has the following transition matrix:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "1/2 & 1/2 & 0 & 0 \\\\\n",
    "1/2 & 0 & 1/2 & 0 \\\\\n",
    "0 & 1/2 & 0 & 1/2 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}$\n",
    "    \n",
    "This chain is reducible since state 4 is absorbing (once entered, cannot be left) and aperiodic. Its stationary distribution is $(0, 0, 0, 1)$.\n",
    "\n",
    "Use the implemented function to verify this chain convergence. Use the next cell to define the necessary variables and call `miniforwardConvergence` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomeSpace_c2 = {\n",
    "    None\n",
    "}\n",
    "\n",
    "transition_c2 = {\n",
    "    None\n",
    "}\n",
    "\n",
    "start_c2 = {\n",
    "    None\n",
    "}\n",
    "\n",
    "printFactor(miniforwardConvergence(start_c2, transition_c2, outcomeSpace_c2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third one has the following transition matrix:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "1/2 & 1/2 & 0 & 0 \\\\\n",
    "1/2 & 1/2 & 0 & 0 \\\\\n",
    "0 & 0 & 1/2 & 1/2 \\\\\n",
    "0 & 0 & 1/2 & 1/2 \\\\\n",
    "\\end{bmatrix}$\n",
    "    \n",
    "This chain is reducible since we cannot reach states {3,4} from states {1,2} and vice-versa and aperiodic. It has two stationary distributions: $(1/2, 1/2, 0, 0)$ and $(0, 0, 1/2, 1/2)$.\n",
    "\n",
    "Use the implemented function to verify this chain convergence. Use the next cell to define the necessary variables and call `miniforwardConvergence` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomeSpace_c3 = {\n",
    "    None\n",
    "}\n",
    "\n",
    "transition_c3 = {\n",
    "    None\n",
    "}\n",
    "\n",
    "start_c3 = {\n",
    "    None\n",
    "}\n",
    "\n",
    "printFactor(miniforwardConvergence(start_c3, transition_c3, outcomeSpace_c3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have a chain in the form:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "1-e & e \\\\\n",
    "e & 1-e \\\\\n",
    "\\end{bmatrix}$\n",
    "    \n",
    "This chain is irreducible and aperiodic, but its convergence can be very slow for small values of $e$. It has one stationary distribution: $(1/2, 1/2)$.\n",
    "\n",
    "Use the implemented function to verify the chain convergence. Change the value of $e$. Use the next cell to define the necessary variables and call `miniforwardConvergence` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0.0001\n",
    "\n",
    "outcomeSpace_c4 = {\n",
    "    None\n",
    "}\n",
    "\n",
    "transition_c4 = {\n",
    "    None\n",
    "}\n",
    "\n",
    "start_c4 = {\n",
    "    None\n",
    "}\n",
    "\n",
    "printFactor(miniforwardConvergence(start_c4, transition_c4, outcomeSpace_c4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# PageRank algorithm\n",
    "\n",
    "The PageRank algorithm is the original algorithm used by Google 1.0. It can be interpreted as a direct application of Markov chains. \n",
    "\n",
    "PageRank models the web as a state graph: pages are states and hyperlinks are transitions. The transition probabilities as set as follows:\n",
    "\n",
    "Imagine you are surfing the web. \n",
    "* With 85% probability, you will jump to the next website by randomly selecting from the links on that page. \n",
    "* With 15% probability, you will jump randomly to any random page on the graph. \n",
    "* If you are at a page with no links, you will always jump to a random page on the graph.\n",
    "\n",
    "Using these transition probabilities, the PageRank algorithm estimates the stationary distribution over webpages, and uses the probabilities of this distribution as an estimate of the \"popularity\" of every webpage.\n",
    "\n",
    "The following figure from [Wikipedia](https://en.wikipedia.org/wiki/PageRank) illustrates the final probabilities (in percentages) of PageRank for a small graph.\n",
    "\n",
    "![](./img/page_rank.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the mini-forward algorithm to implement the PageRank algorithm. We will use this figure to compare our results. We start by defining this graph. We will do it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha sets the weight portion reserved for regular edges\n",
    "alpha = .85\n",
    "\n",
    "outcomePageRank = {\n",
    "    \"P_t-1\":('A','B','C','D','E','F','G','H','I','J','K'),\n",
    "    \"P_t\":('A','B','C','D','E','F','G','H','I','J','K'),\n",
    "}\n",
    "\n",
    "page_graph = {\n",
    "    \"A\" : [],\n",
    "    'B' : ['C'],\n",
    "    'C' : ['B'],\n",
    "    'D' : ['B','A'],\n",
    "    'E' : ['B','D','F'],\n",
    "    'F' : ['B','E'],\n",
    "    'G' : ['B','E'],\n",
    "    'H' : ['B','E'],\n",
    "    'I' : ['B','E'],\n",
    "    'J' : ['E'],\n",
    "    'K' : ['E'],\n",
    "}\n",
    "\n",
    "# We set all states with equal initial probabilities\n",
    "startPageRank = {\n",
    "    'dom': ('P',), \n",
    "    'table': odict([\n",
    "        (('A',), .091),\n",
    "        (('B',), .091),\n",
    "        (('C',), .091),\n",
    "        (('D',), .091),\n",
    "        (('E',), .091),\n",
    "        (('F',), .091),\n",
    "        (('G',), .091),\n",
    "        (('H',), .091),\n",
    "        (('I',), .091),\n",
    "        (('J',), .091),\n",
    "        (('K',), .091),        \n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Fill in the function below to create a transition table according to the rules above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTransitionTable(graph, alpha=0.85):\n",
    "    N = len(graph)\n",
    "    phantomTransition = {'dom': ('P_t-1', 'P_t'), 'table': odict([])}\n",
    "    \n",
    "    # for every pair of nodes in the graph\n",
    "    for u in outcomePageRank['P_t-1']:\n",
    "        for v in outcomePageRank['P_t']:\n",
    "            # find the number of outgoing links\n",
    "            out_degree = len(graph[u])\n",
    "            if out_degree == 0:\n",
    "                # starting at a node 'u' with no neighbors, what's the probability of jumping to v?\n",
    "                prob_v_given_u = None                                                 # 1 line\n",
    "            else:\n",
    "                if v in graph[u]:\n",
    "                    # starting at 'u', the probability of jumping to a connected node 'v'. \n",
    "                    # (Make sure you take into account the 15% possibility of randomly jumping to any node)\n",
    "                    prob_v_given_u = None                                             # 1 line\n",
    "                else:\n",
    "                    # starting at 'u', the probability of jumping to a random node 'v'\n",
    "                    prob_v_given_u = None                                             # 1 line\n",
    "            phantomTransition['table'][(u,v)] = prob_v_given_u\n",
    "    return phantomTransition\n",
    "            \n",
    "pageRankTransition = createTransitionTable(page_graph)\n",
    "printFactor(pageRankTransition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use ``GraphViz`` again to plot this graph and ensure we have designed it correctly. Note that we will not print all $11^2$ conditional probabilities, only the ones that correspond to following a link in the above graph. For a node with one outgoing edge, that edge should have a probability of $0.85 + 0.15\\times(1/11) \\approx 0.864 $, which is the sum of the probability of following the link $85$% and the probability of randomly choosing the connected node $15\\%\\times(1/11)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dot = Digraph(engine=\"neato\", comment='PageRank Markov chain')\n",
    "dot.attr(overlap=\"false\", splines=\"false\", strict=\"true\")\n",
    "\n",
    "pos = {\n",
    "    'A': '0,2!',\n",
    "    'B': '2,2!',\n",
    "    'C': '4,2!',\n",
    "    'D': '0,1!',\n",
    "    'E': '3,1!',\n",
    "    'F': '4,1!',\n",
    "    'G': '0,0!',\n",
    "    'H': '1,0!',\n",
    "    'I': '2,0!',\n",
    "    'J': '3,0!',\n",
    "    'K': '4,0!',\n",
    "}\n",
    "\n",
    "for v in outcomePageRank['P_t']:\n",
    "    dot.node(v, pos=pos[v])\n",
    "\n",
    "for v in page_graph:\n",
    "    for w in page_graph[v]:\n",
    "        if (v,w) in pageRankTransition['table'].keys():\n",
    "            dot.edge(v, w, str(round(pageRankTransition['table'][(v,w)],3)))\n",
    "\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_rank = miniforwardConvergence(startPageRank, pageRankTransition, outcomePageRank)\n",
    "printFactor(page_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ``GraphViz`` to visualise the results of the PageRank algorithm implementation. The next cell tries to mimic the Wikipedia figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = Digraph(engine=\"neato\", comment='PageRank Markov chain')\n",
    "dot.attr(overlap=\"false\", splines=\"false\", strict=\"true\")\n",
    "\n",
    "pos = {\n",
    "    'A': '0,2!',\n",
    "    'B': '2,2!',\n",
    "    'C': '4,2!',\n",
    "    'D': '0,1!',\n",
    "    'E': '3,1!',\n",
    "    'F': '4,1!',\n",
    "    'G': '0,0!',\n",
    "    'H': '1,0!',\n",
    "    'I': '2,0!',\n",
    "    'J': '3,0!',\n",
    "    'K': '4,0!',\n",
    "}\n",
    "\n",
    "for v in outcomePageRank['P_t']:\n",
    "    dot.node(v, pos=pos[v], label=v+'\\n'+str(round(page_rank['table'][(v,)]*100,1)))\n",
    "\n",
    "for v in outcomePageRank['P_t']:\n",
    "    for w in outcomePageRank['P_t']:\n",
    "        if (v,w) in pageRankTransition['table'].keys():\n",
    "            dot.edge(v, w)\n",
    "\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/page_rank.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Models (HMMs)\n",
    "\n",
    "We now turn our attention to HMMs. These are popular dynamic Bayesian Networks. We will implement the forward and Viterbi algorithms and verify how these algorithms provide answers to the questions on the theory part of this tutorial.\n",
    "\n",
    "We start with the forward algorithm. According to the lecture slides, the forward algorithm for HMMs has the following form:\n",
    "\n",
    "1. The transition step is similar to Markov chains. In this step, we have a passage of time and the distribution moves towards the stationary distribution.\n",
    "\n",
    "    $P(x_t|e_{1:t-1}) = \\sum_{x_{t-1}}P(x_{t-1}|e_{1:t-1})P(x_t|x_{t-1})$\n",
    "\n",
    "    where, $P(x_t|e_{1:t-1})$ is the current state before observing the evidence $e_t$. $P(x_{t-1}|e_{1:t-1})$ is the previous state and $P(x_t|x_{t-1})$ is the transition probability.\n",
    "\n",
    "\n",
    "2. The emission step has the following form:\n",
    "\n",
    "    $P(x_t|e_{1:t}) \\propto P(x_t|e_{1:t-1})P(e_t|x_t)$\n",
    "\n",
    "    where, $P(x_t|e_{1:t-1})$ is the current state after observing the evidence $e_t$. $P(x_t|e_{1:t-1})$ is the current state before observing de evidence (obtained in the previous step) and $P(e_t|x_t)$ is the emission probability.\n",
    "\n",
    "\n",
    "The symbol $\\propto$ means that the emission step requires a normalization. The normalization is necessary because we are omitting the denominator in the emission update. The denominator is the probability of the evidence, which we frequently do not have readily available. Although we can compute such quantity, the normalization is usually easier to calculate.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Let's implement the forward algorithm for HMMs. From the above equations, we will need to set the evidence and renormalize factors. Therefore, we bring these functions from previous tutorials to the next cell. We recommend you use your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evidence(var, e, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `var`, a valid variable identifier.\n",
    "    `e`, the observed value for var.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns dictionary with a copy of outcomeSpace with var = e\n",
    "    \"\"\"    \n",
    "    newOutcomeSpace = outcomeSpace.copy()      # Make a copy of outcomeSpace\n",
    "    newOutcomeSpace[var] = (e,)                # Replace the domain of variable var with a tuple with a single element e. 1 line\n",
    "    return newOutcomeSpace\n",
    "\n",
    "def normalize(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be normalized.\n",
    "    \n",
    "    Returns a new factor f' as a copy of f with entries that sum up to 1\n",
    "    \"\"\" \n",
    "    table = list()\n",
    "    sum = 0\n",
    "    for k, p in f['table'].items():\n",
    "        sum = sum + p\n",
    "    for k, p in f['table'].items():\n",
    "        table.append((k, p/sum))\n",
    "    return {'dom': f['dom'], 'table': odict(table)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are in position now to implement the online version of forward algorithm for HMMs. This function will compute just one step of the forward algorithm. Such a step is composed by one time passage plus one observation of evidence.\n",
    "\n",
    "To make this function more flexible, we will allow the user to pass an empty emission value. This means that no evidence was observed in this step. Also, the renormalization will be optional, so we will keep it commented for now.\n",
    "\n",
    "Let us code this function. We have created a stub for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardOnline(f, transition, emission, stateVar, emissionVar, emissionEvi, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor that represents the previous state.\n",
    "    `transition`, transition probabilities from time t-1 to t.\n",
    "    `emission`, emission probabilities.\n",
    "    `stateVar`, state (hidden) variable.\n",
    "    `emissionVar`, emission variable.\n",
    "    `emissionEvi`, emission observed evidence. If undef, we do only the time update\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.\n",
    "    \n",
    "    Returns a new factor that represents the current state.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set fCurrent as a copy of f\n",
    "    fCurrent = f.copy();\n",
    "    # Set the f_previous domain to be a list with a single variable name appended with '_t-1' to indicate previous time step\n",
    "    fCurrent['dom'] = (stateVar + '_t-1', )       \n",
    "    # Make the join operation between fCurrent and the transition probability table\n",
    "    fCurrent = join(fCurrent, transition, outcomeSpace)\n",
    "    # Marginalize the randVariable_t-1\n",
    "    fCurrent = None                                                                          # 1 line\n",
    "    # If emissionEvi == None, we will assume this time step has no observed evidence\n",
    "    if emissionEvi != None:                                                         # WARNING! Do not change this line\n",
    "        # Set evidence in the form emissionVar = emissionEvi\n",
    "        newOutcomeSpace = None                                                              # 1 line\n",
    "        # Make the join operation between fCurrent and the emission probability table. Use the newOutcomeSpace\n",
    "        fCurrent = None                                                                     # 1 line\n",
    "        # Marginalize emissionVar. Use the newOutcomeSpace\n",
    "        fCurrent = None                                                                     # 1 line\n",
    "        # Normalize fCurrent, optional step. Keep the next line commented for now\n",
    "        # fCurrent = None\n",
    "    # Set the domain of w to be name of the random variable without time index\n",
    "    fCurrent['dom'] = (stateVar, )\n",
    "    return fCurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the weather example from the lecture to test our implementation. In this example, a graduate student tries to figure out the current weather state by observing this advisor carrying an umbrella.\n",
    "\n",
    "These are the transition and emission probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Test code\n",
    "\n",
    "# possible outcomes, by variable\n",
    "outcomeSpace = {\n",
    "    'Weather_t-1':('sun','rain'),\n",
    "    'Weather_t':('sun','rain'),\n",
    "    'Umbrella_t': ('umbrella', 'no_umbrella'),\n",
    "}\n",
    "\n",
    "# The start state, in this case let's assume we start in a sunny day\n",
    "weatherStart = {\n",
    "    'dom': ('Weather',), \n",
    "    'table': odict([\n",
    "        (('sun',), 0.5),\n",
    "        (('rain',), 0.5),\n",
    "    ])\n",
    "}\n",
    "\n",
    "weatherTransition = {\n",
    "    'dom': ('Weather_t-1', 'Weather_t'), \n",
    "    'table': odict([\n",
    "        (('sun','sun'), 0.7),\n",
    "        (('sun','rain'), 0.3),\n",
    "        (('rain','sun'), 0.3),\n",
    "        (('rain','rain'), 0.7),\n",
    "    ])\n",
    "}\n",
    "\n",
    "weatherEmission = {\n",
    "    'dom': ('Weather_t', 'Umbrella_t'), \n",
    "    'table': odict([\n",
    "        (('sun','umbrella'), 0.2),\n",
    "        (('sun','no_umbrella'), 0.8),\n",
    "        (('rain','umbrella'), 0.9),\n",
    "        (('rain','no_umbrella'), 0.1),        \n",
    "    ])\n",
    "}\n",
    "\n",
    "printFactor(forwardOnline(weatherStart, weatherTransition, weatherEmission, 'Weather', 'Umbrella_t', 'umbrella', outcomeSpace))\n",
    "print()\n",
    "printFactor(forwardOnline(weatherStart, weatherTransition, weatherEmission, 'Weather', 'Umbrella_t', None, outcomeSpace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented your code correctly, you should see an output like this:\n",
    "\n",
    "```\n",
    "| Weather   |   Pr |\n",
    "|-----------+------|\n",
    "| sun       | 0.1  |\n",
    "| rain      | 0.45 |\n",
    "\n",
    "| Weather   |   Pr |\n",
    "|-----------+------|\n",
    "| sun       |  0.5 |\n",
    "| rain      |  0.5 |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Let's now implement the batch version of the forward algorithm. The batch version takes as input a sequence of `n` observations and outputs an array of length `n` with the state distribution at each time step.\n",
    "\n",
    "We have created a stub for you. You should pass as argument a list of evidence observations. Call the online version of the algorithm as many times as you have items in the emissionEviList."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardBatch(f, transition, emission, stateVar, emissionVar, emissionEviList, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor that represents the previous state.\n",
    "    `transition`, transition probabilities from time t-1 to t.\n",
    "    `emission`, emission probabilities.\n",
    "    `stateVar`, state (hidden) variable.\n",
    "    `emissionVar`, emission variable.\n",
    "    `emissionEviList`, emission observed evidence.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.\n",
    "    \n",
    "    Returns a vector with all state distributions over time.\n",
    "    \"\"\"\n",
    "    timeLine = []\n",
    "    # Set fCurrent as a copy of f\n",
    "    fCurrent = f.copy()\n",
    "    for emissionEvi in emissionEviList:\n",
    "        # Call the online version of the forward algorithm to update one time step\n",
    "        fCurrent = None                                                                    # 1 line\n",
    "        timeLine.append(fCurrent)\n",
    "    return timeLine\n",
    "\n",
    "#################\n",
    "# Test code\n",
    "timeLine = forwardBatch(weatherStart, weatherTransition, weatherEmission, 'Weather', 'Umbrella_t', ('umbrella', 'umbrella'), outcomeSpace)\n",
    "for t in range(len(timeLine)):\n",
    "    print(\"Time: \", t)\n",
    "    printFactor(timeLine[t])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If your implementation is correct. You should see an output like this one:\n",
    "\n",
    "Time:  0\n",
    "| Weather   |   Pr |\n",
    "|-----------+------|\n",
    "| sun       | 0.1  |\n",
    "| rain      | 0.45 |\n",
    "\n",
    "Time:  1\n",
    "| Weather   |     Pr |\n",
    "|-----------+--------|\n",
    "| sun       | 0.041  |\n",
    "| rain      | 0.3105 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement the Viterbi algorithm. The Viterbi algorithm provides answers to queries in the form of the most likely explanation (MLE). In other words, the output will be the most likely instantiation for each of the hidden states.\n",
    "\n",
    "According to the course slides, the Viterbi algorithm has the following equations:\n",
    "\n",
    "$m_t[x_t] = P(e_t|x_t) max_{x_{t-1}}P(x_t|x_{t-1})m_{t-1}[x_{t-1}]$\n",
    "\n",
    "where, \n",
    "\n",
    "- $m_t[x_t]$ is the MLE for time $t$.\n",
    "- $P(e_t|x_t)$ is the emission probability.\n",
    "- $P(x_t|x_{t-1})$ is the transition probability.\n",
    "- $m_{t-1}[x_{t-1}]$ is the MLE for time $t-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "To implement the Viterbi algorithm, we will need an intermediate operation `maximize`. Such an operation is similar to `marginalize` in the sense that it will eliminate one variable of a factor. However, instead of summing out this variable, we will compute the maximum among the entries.\n",
    "\n",
    "We have created a stub for you. You will need to complete a few gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize(f, var, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be marginalized.\n",
    "    `var`, variable to be maximized out.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor f' with dom(f') = dom(f) - {var}\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Let's make a copy of f domain and convert it to a list. We need a list to be able to modify its elements\n",
    "    new_dom = list(f['dom'])\n",
    "    new_dom.remove(var)            # Remove var from the list new_dom by calling the method remove(). 1 line\n",
    "    table = list()                 # Create an empty list for table. We will fill in table from scratch. 1 line\n",
    "    for entries in product(*[outcomeSpace[node] for node in new_dom]):\n",
    "        #########################\n",
    "        # Insert your code here #\n",
    "        #########################        \n",
    "        m = None;                    # Initialize the maximization variable m. 1 line\n",
    "\n",
    "        # We need to iterate over all possible outcomes of the variable var\n",
    "        for val in outcomeSpace[var]:\n",
    "            # To modify the tuple entries, we will need to convert it to a list\n",
    "            entriesList = list(entries)\n",
    "            # We need to insert the value of var in the right position in entriesList\n",
    "            entriesList.insert(f['dom'].index(var), val)\n",
    "            \n",
    "            #########################\n",
    "            # Insert your code here #\n",
    "            #########################\n",
    "            p = None                        # Calculate the probability of factor f for entriesList. 1 line\n",
    "            m = None                        # Maximize over all values of var by storing the max value in m. 1 line\n",
    "            \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, m))\n",
    "    return {'dom': tuple(new_dom), 'table': odict(table)}\n",
    "\n",
    "################\n",
    "# Test code\n",
    "\n",
    "printFactor(maximize(weatherEmission, 'Umbrella_t', outcomeSpace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "def maximize(f, var, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be marginalized.\n",
    "    `var`, variable to be maximized out.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor f' with dom(f') = dom(f) - {var}\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Let's make a copy of f domain and convert it to a list. We need a list to be able to modify its elements\n",
    "    new_dom = list(f['dom'])\n",
    "    \n",
    "    new_dom.remove(var)            # Remove var from the list new_dom by calling the method remove(). 1 line\n",
    "    table = list()                 # Create an empty list for table. We will fill in table from scratch. 1 line\n",
    "    for entries in product(*[outcomeSpace[node] for node in new_dom]):\n",
    "        m = -1;                    # Initialize the maximization variable m. 1 line\n",
    "\n",
    "        # We need to iterate over all possible outcomes of the variable var\n",
    "        for val in outcomeSpace[var]:\n",
    "            # To modify the tuple entries, we will need to convert it to a list\n",
    "            entriesList = list(entries)\n",
    "            # We need to insert the value of var in the right position in entriesList\n",
    "            entriesList.insert(f['dom'].index(var), val)\n",
    "\n",
    "            p = prob(f, *tuple(entriesList))     # Calculate the probability of factor f for entriesList. 1 line\n",
    "            m = max(m, p)                        # Maximize over all values of var by storing the max value in m. 1 line\n",
    "            \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, m))\n",
    "    return {'dom': tuple(new_dom), 'table': odict(table)}\n",
    "\n",
    "################\n",
    "# Test code\n",
    "\n",
    "printFactor(maximize(weatherEmission, 'Umbrella_t', outcomeSpace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should see the following output:\n",
    "\n",
    "```\n",
    "| Weather_t   |   Pr |\n",
    "|-------------+------|\n",
    "| sun         |  0.8 |\n",
    "| rain        |  0.9 |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Now we are in the position to implement the Viterbi algorithm. We have started the implementation and left a few details for you to fill in. As before, we will code the online version first. The online version provides the output for a single time and evidence observation increment. The batch version is a simple extension of the online algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbiOnline(f, transition, emission, stateVar, emissionVar, emissionEvi, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor that represents the previous state.\n",
    "    `transition`, transition probabilities from time t-1 to t.\n",
    "    `emission`, emission probabilities.\n",
    "    `stateVar`, state (hidden) variable.\n",
    "    `emissionVar`, emission variable.\n",
    "    `emissionEvi`, emission observed evidence. If undef, we do only the time update\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.\n",
    "    \n",
    "    Returns a new factor that represents the current state.\n",
    "    \"\"\" \n",
    "\n",
    "    # Set fCurrent as a copy of f\n",
    "    fCurrent = f.copy();\n",
    "    # Set the f_previous domain to be a list with a single variable name appended with '_t-1' to indicate previous time step\n",
    "    fCurrent['dom'] = (stateVar + '_t-1', )       \n",
    "    # Make the join operation between fCurrent and the transition probability table    \n",
    "    fCurrent = None                                                                    # 1 line\n",
    "    # Eliminate the randVariable_t-1 with the maximization operation\n",
    "    fCurrent = None                                                                    # 1 line\n",
    "    # If emissionEvi == None, we will assume this time step has no observed evidence    \n",
    "    if emissionEvi != None:                                                            # WARNING: do not change this line\n",
    "        # Set evidence in the form emissionVar = emissionEvi    \n",
    "        newOutcomeSpace = None                                                         # 1 line\n",
    "        # Make the join operation between fCurrent and the emission probability table. Use the newOutcomeSpace    \n",
    "        fCurrent = None                                                                # 1 line\n",
    "        # Marginalize emissionVar. Use the newOutcomeSpace    \n",
    "        fCurrent = None                                                                # 1 line       \n",
    "        # Normalize fcurrent. Keep the next line commented for now\n",
    "        # fCurrent = None                                                              # 1 line\n",
    "    # Set the domain of w to be name of the random variable without time index\n",
    "    fCurrent['dom'] = (stateVar, )\n",
    "    return fCurrent\n",
    "\n",
    "##################\n",
    "# Test code\n",
    "\n",
    "printFactor(viterbiOnline(weatherStart, weatherTransition, weatherEmission, 'Weather', 'Umbrella_t', 'umbrella', outcomeSpace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should see the following output:\n",
    "\n",
    "```\n",
    "| Weather   |    Pr |\n",
    "|-----------+-------|\n",
    "| sun       | 0.07  |\n",
    "| rain      | 0.315 |\n",
    "```\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Now, implement the batch version of the Viterbi algorithm by calling the online function multiple times. Call the online version once for each observation in `emissionEviList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbiBatch(f, transition, emission, stateVar, emissionVar, emissionEviList, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor that represents the previous state.\n",
    "    `transition`, transition probabilities from time t-1 to t.\n",
    "    `emission`, emission probabilities.\n",
    "    `stateVar`, state (hidden) variable.\n",
    "    `emissionVar`, emission variable.\n",
    "    `emissionEviList`, emission observed evidence.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.\n",
    "    \n",
    "    Returns a new factor that represents the current state.\n",
    "    \"\"\"      \n",
    "    timeLine = []\n",
    "    # Set fCurrent as a copy of f\n",
    "    fCurrent = f.copy()\n",
    "    for emissionEvi in emissionEviList:\n",
    "        # Call the online version of the Viterbi algorithm to update one time step\n",
    "        fCurrent = None                                                                    # 1 line\n",
    "        # Print the current factor for debugging\n",
    "        timeLine.append(fCurrent)\n",
    "    return timeLine\n",
    "\n",
    "#################\n",
    "# Test code\n",
    "timeLine = viterbiBatch(weatherStart, weatherTransition, weatherEmission, 'Weather', 'Umbrella_t', ('umbrella', 'umbrella'), outcomeSpace)\n",
    "for t in range(len(timeLine)):\n",
    "    print(\"Time: \", t)\n",
    "    printFactor(timeLine[t])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should see the following output:\n",
    "\n",
    "```\n",
    "Time:  0\n",
    "| Weather   |    Pr |\n",
    "|-----------+-------|\n",
    "| sun       | 0.07  |\n",
    "| rain      | 0.315 |\n",
    "\n",
    "Time:  1\n",
    "| Weather   |      Pr |\n",
    "|-----------+---------|\n",
    "| sun       | 0.0189  |\n",
    "| rain      | 0.19845 |\n",
    "```\n",
    "\n",
    "Before we conclude with an exercise, here are some suggestions of ways to improve the source code of this tutorial:\n",
    "\n",
    "1. The forward algorithm typically does not normalize the intermediate results. You can make this step optional with a flag. This change can also be done to the Viterbi algorithm.\n",
    "\n",
    "2. If you do not normalize, the probabilities will assume small values due to the sequence of multiplications. In this case, operating with log-probabilities will decrease the chance of having underflows.\n",
    "\n",
    "3. For simplicity, we are assuming the update steps are composed by a transition followed by emission. But it is not always the case. It would be better if these steps can be inverted or, even better, implemented independently.\n",
    "\n",
    "## Finding the MPE Assignment\n",
    "\n",
    "As we discussed in the lecture, we can find the MPE assigment from the output computed by the Viterbi algorithm. Remember, that the correct assignment is obtained when we trace back the computations, starting with the last state and move towards the first state. There are two main approaches for finding the MPE assignment:\n",
    "\n",
    "1. Use an additional data structure to store pointers indicating the path of the highest probability.\n",
    "\n",
    "2. Use the output of the Viterbi algorithm and trace back the computations.\n",
    "\n",
    "In the next cell, we provide a function to find the MPE assignment given the output of the ``viterbi`` function. The ``traceback`` function has some technical difficulties due to the need to deal with zero probabilities (which could cause a division by zero in the trace back procedure) and comparison of float numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traceBack(timeLine, start, transition, emission, stateVar, emissionVar, emissionEviList, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor that represents the previous state.\n",
    "    `transition`, transition probabilities from time t-1 to t.\n",
    "    `emission`, emission probabilities.\n",
    "    `stateVar`, state (hidden) variable.\n",
    "    `emissionVar`, emission variable.\n",
    "    `emissionEviList`, emission observed evidence.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.\n",
    "    \n",
    "    Returns an array with the MLE assignment.\n",
    "    \"\"\" \n",
    "\n",
    "    t = len(timeLine) - 1\n",
    "    mleList = [outcomeSpace[stateVar][0]] * (t+1)\n",
    "    mleList[t] = max(timeLine[t]['table'], key=timeLine[t]['table'].get)[0]\n",
    "    p = prob(timeLine[t], mleList[t])\n",
    "    for t in range(t,0,-1):\n",
    "        p_e = prob(emission, mleList[t], emissionEviList[t])\n",
    "        for state in outcomeSpace[stateVar]:\n",
    "            p_t = prob(transition, state, mleList[t])\n",
    "            if p_t != 0 and p_e!=0:\n",
    "                if abs(prob(timeLine[t-1], state) - p/p_e/p_t) < 0.00000001:\n",
    "                    mleList[t-1] = state\n",
    "                    p = prob(timeLine[t-1], state)\n",
    "    p_e = prob(emission, mleList[0], emissionEviList[0])\n",
    "    for state in outcomeSpace[stateVar]:\n",
    "        p_t = prob(transition, state, mleList[0])\n",
    "        if p_t != 0 and p_e != 0:       \n",
    "            if abs(prob(start, state) - p/p_e/p_t) < 0.00000001:\n",
    "                mleList[0] = state\n",
    "                p = prob(timeLine[0], state)\n",
    "    return mleList\n",
    "\n",
    "####################\n",
    "## Test code\n",
    "\n",
    "mpe = traceBack(timeLine, weatherStart, weatherTransition, weatherEmission, 'Weather_t', 'Umbrella_t', ('umbrella', 'umbrella'), outcomeSpace)\n",
    "print(mpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "You can use the implemented code to find the numerical answers to the questions of the theory part of this tutorial.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Lisa is given a fair coin $C_1$ and asked to flip it eight times in a row. Lisa also has a biased coin $C_2$ with probability 0.8 of landing heads. All we know is that Lisa flipped the fair coin initially but we believe that she intends to switch to the biased coin and that she tends to be 10% successful in performing the switch. Suppose that we observe the outcome of the eight coin flips and want to find out whether Lisa managed to perform a coin switch and when. What is the solution to this problem assuming that the flips came out as follows:\n",
    "\n",
    "    a. tails, tails, tails, heads, heads, heads, heads, heads\n",
    "    b. tails, tails, heads, heads, heads, heads, heads, heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outcomeSpaceLisa = {\n",
    "    \"C_t\":('fair','biased'),\n",
    "    \"C_t-1\":('fair','biased'),\n",
    "}\n",
    "\n",
    "transitionLisa = {\n",
    "    'dom': ('C_t-1', 'C_t'), \n",
    "    'table': odict([\n",
    "        (('fair','fair'), 0.9),\n",
    "        (('fair','biased'), 0.1),\n",
    "        (('biased','fair'), 0.0),\n",
    "        (('biased','biased'), 1.0),        \n",
    "    ])\n",
    "}\n",
    "\n",
    "startLisa = {\n",
    "    'dom': ('C',), \n",
    "    'table': odict([\n",
    "        (('fair',), 1.0),\n",
    "        (('biased',), 0.0),\n",
    "    ])\n",
    "}\n",
    "\n",
    "evidenceLisa = {\n",
    "    'dom': ('C_t', 'U_t'), \n",
    "    'table': odict([\n",
    "        (('fair','heads'), 0.5),\n",
    "        (('fair','tails'), 0.5),\n",
    "        (('biased','heads'), 0.8),\n",
    "        (('biased','tails'), 0.2),\n",
    "    ])\n",
    "}\n",
    "\n",
    "evidenceOutcomes = ('tails', 'tails', 'tails', 'heads', 'heads', 'heads', 'heads', 'heads')\n",
    "    \n",
    "# Exercise: Use the functions created above to answer Q1a\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "evidenceOutcomes = ('tails', 'tails', 'heads', 'heads', 'heads', 'heads', 'heads', 'heads')\n",
    "\n",
    "# Exercise: Use the functions created above to answer Q1b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Consider a cow that may be infected with a disease that can possibly be detected by performing a milk test. The test is performed on five consecutive days, leading to five outcomes. We want to determine the state of the cow's infection over these days given the test outcomes. The prior probability of an infection on day one is 1/10,000; the test false positive rate is 5/1,000; and its false negative rate is 1/1,000. Moreover, the state of infection at a given day depends only on its state at the previous day. In particular, the probability of a new infection on a given day is 2/10,000, while the probability that an infection would persist to the next day os 7/10.\n",
    "\n",
    "What is the most likely state of the cow's infection over the five days given the following test outcomes:\n",
    "\n",
    "    a. positive, positive, negative, positive, positive\n",
    "    b. positive, negative, negative, positive, positive\n",
    "    c. positive, nagetive, negative, negative, positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomeSpaceCow = {\n",
    "    \"Cow_t\":('healthy','infected'),\n",
    "    \"Cow_t-1\":('healthy','infected'),\n",
    "}\n",
    "\n",
    "transitionCow = {\n",
    "    'dom': ('Cow_t-1', 'Cow_t'), \n",
    "    'table': odict([\n",
    "        (('healthy','healthy'), 9998/10000),\n",
    "        (('healthy','infected'), 2/10000),\n",
    "        (('infected','healthy'), 3/10),\n",
    "        (('infected','infected'), 7/10),        \n",
    "    ])\n",
    "}\n",
    "\n",
    "startCow = {\n",
    "    'dom': ('Cow',), \n",
    "    'table': odict([\n",
    "        (('healthy',), 9999/10000),\n",
    "        (('infected',), 1/10000),\n",
    "    ])\n",
    "}\n",
    "\n",
    "evidenceCow = {\n",
    "    'dom': ('Cow_t', 'Test_t'), \n",
    "    'table': odict([\n",
    "        (('healthy','positive'), 5/1000),\n",
    "        (('healthy','negative'), 995/1000),\n",
    "        (('infected','positive'), 999/1000),\n",
    "        (('infected','negative'), 1/1000),\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Exercise: Use the functions created above to answer Q2: a,b and c.\n",
    "\n",
    "a = ('positive', 'positive', 'negative', 'positive', 'positive')\n",
    "b = ('positive', 'negative', 'negative', 'positive', 'positive')\n",
    "c = ('positive', 'positive', 'negative', 'positive', 'positive')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "198px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
